# -*- coding: utf-8 -*-
"""FRA LDSS: Task 10.1 Analysis - Services by State.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Och9qG05qy53uUB3krWGZ9-MMYUYrimp

### Preparation

Read the Amtrak GTFS data. We need four text files: routes, trips, stops, and stop times. In addition, we gathered the route type information from Wikipedia: https://en.wikipedia.org/wiki/List_of_Amtrak_routes
"""

!git clone https://github.com/RobertZhangAECOM/FRA-LDSS-Task-10.1-Analysis.git
import pandas as pd
routes = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/routes.txt')
trips = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/trips.txt')
stops = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/stops.txt')
stop_times = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/stop_times.txt')
route_types = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/routetype.csv')

"""We utilize the geopy library to perform reverse geocoding and determine the state associated with each stop in the stops DataFrame."""

from geopy.geocoders import Nominatim
geolocator = Nominatim(user_agent="getstates", timeout=10)

def get_state(row):
  lat = row['stop_lat']
  lon = row['stop_lon']
  location = geolocator.reverse(f"{lat}, {lon}")
  address = location.raw['address']
  state = address.get('state')
  if not state:
      state = address.get('yes') # Extra Case for PA
  return state

stops['state'] = stops.apply(get_state, axis=1)

"""We need to create a summary table with 50 US states and District of Columbia. Also, we need to get Amtrak routes by filtering agency_id = 51 on routes.txt."""

!pip install us
import us
all_states = [state.name for state in us.states.STATES]
all_states.append("District of Columbia")

routes = routes[routes['agency_id'] == 51]

"""### Baseline Routes DataFrame

Create a new dataframe: df_baseline. Select trip id and stop id from stop_times.txt. Then lookup the route id from trips.txt and route name from the route.txt. After that, merge the route types from route_types.csv and stop names and states from stops.txt.
"""

df_baseline = stop_times[['trip_id', 'stop_id']]
df_baseline = pd.merge(df_baseline, trips[['trip_id', 'route_id']], on='trip_id', how='left')
df_baseline = pd.merge(df_baseline, routes[['route_id', 'route_long_name']], on='route_id', how='left')
df_baseline = pd.merge(df_baseline, route_types, on='route_long_name', how='left')
df_baseline = pd.merge(df_baseline, stops[['stop_id', 'stop_name', 'state']], on='stop_id', how='left')

"""Group by state and route_type, and count unique route_ids. Then pivot the grouped DataFrame to get the desired format."""

grouped = df_baseline.groupby(['state', 'route_type'])['route_id'].nunique().reset_index()
pivot = grouped.pivot(index='state', columns='route_type', values='route_id').fillna(0).reset_index()
df_summary = pd.DataFrame(sorted(all_states), columns=['state'])
df_summary = df_summary.merge(pivot, on='state', how='left').fillna(0)

"""### Preferred Routes DataFrame

We read the preferred route CSV file containing route information and extracts state abbreviations from the station column. Then we use the us package to map these abbreviations to their full state names. Finally, we count unique routes by state and rename columns.
"""

df_preferred = pd.read_csv('/content/FRA-LDSS-Task-10.1-Analysis/preferred_routes.csv')
df_preferred['state_abbr'] = df_preferred['station'].str.extract(r',\s*(\w{2})')

def get_state_name(state_abbr):
    if state_abbr == 'DC':
        return 'District of Columbia'
    state = us.states.lookup(state_abbr)
    return state.name if state else ''

df_preferred['state_name'] = df_preferred['state_abbr'].apply(get_state_name)
df_preferred = df_preferred.groupby('state_name')['route'].nunique().reset_index()
df_preferred.columns = ['state', 'Preferred LD']

"""### Merge and Format Data

We merge dataframes and fill missing values. Also, we format the table by converting float to integer and reordering columns.
"""

df = pd.merge(df_summary, df_preferred, on='state', how='left').fillna(0)
df[df.select_dtypes(include=['float']).columns] = df.select_dtypes(include=['float']).astype(int)
df = df[['state', 'Long-Distance', 'State-Supported', 'NEC', 'State-Supported; NEC', 'Preferred LD']]
df